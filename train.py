# train.py
import torch
from torch.utils.data import DataLoader
from model import SimpleViT
from engine import BiasCorrectTrainer, QuantileDataset


def train_bias_correction(
    lr_q_train, hr_q_train, 
    lr_q_val, hr_q_val,
    quantiles, 
    config,
    normalization=None,  # â­ ìƒˆ íŒŒë¼ë¯¸í„°
    lr_stats=None,  # Deprecated (í•˜ìœ„ í˜¸í™˜ì„±)
    hr_stats=None   # Deprecated (í•˜ìœ„ í˜¸í™˜ì„±)
):
    """
    í¸ì´ë³´ì • í•™ìŠµ
    
    Parameters:
    -----------
    lr_q_train, hr_q_train : numpy.ndarray
        í›ˆë ¨ ë¶„ìœ„ìˆ˜ ë§µ [n_quantiles, H, W], [0, 1] ì •ê·œí™”ë¨
    lr_q_val, hr_q_val : numpy.ndarray
        ê²€ì¦ ë¶„ìœ„ìˆ˜ ë§µ [n_quantiles, H, W], [0, 1] ì •ê·œí™”ë¨
    quantiles : numpy.ndarray
        ë¶„ìœ„ìˆ˜ ë°°ì—´ [0, 100]
    config : dict
        í•™ìŠµ ì„¤ì •
    normalization : dict
        ì •ê·œí™” ì •ë³´ {'type': 'fixed_range', 'lr_min': 260, 'lr_max': 320, ...}
    """
    
    print("="*60)
    print("ğŸš€ Starting Training Pipeline")
    print("="*60)
    
    # 1. ë°ì´í„° ë²”ìœ„ í™•ì¸
    print(f"\nğŸ“Š Input data info:")
    print(f"   LR train: {lr_q_train.shape}, range=[{lr_q_train.min():.3f}, {lr_q_train.max():.3f}]")
    print(f"   HR train: {hr_q_train.shape}, range=[{hr_q_train.min():.3f}, {hr_q_train.max():.3f}]")
    print(f"   LR val:   {lr_q_val.shape}, range=[{lr_q_val.min():.3f}, {lr_q_val.max():.3f}]")
    print(f"   HR val:   {hr_q_val.shape}, range=[{hr_q_val.min():.3f}, {hr_q_val.max():.3f}]")
    
    if normalization is not None:
        print(f"\nğŸ“Š Normalization:")
        print(f"   Type: {normalization['type']}")
        if normalization['type'] == 'fixed_range':
            print(f"   LR: [{normalization['lr_min']}K, {normalization['lr_max']}K]")
            print(f"   HR: [{normalization['hr_min']}K, {normalization['hr_max']}K]")
    
    # 2. Dataset ìƒì„± (ë²”ìœ„ ê²€ì¦ í¬í•¨)
    print(f"\nğŸ“¦ Creating datasets...")
    train_dataset = QuantileDataset(
        lr_q_train, hr_q_train, 
        verify_range=True  # â­ ë²”ìœ„ ê²€ì¦
    )
    val_dataset = QuantileDataset(
        lr_q_val, hr_q_val, 
        verify_range=True  # â­ ë²”ìœ„ ê²€ì¦
    )
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config['batch_size'],
        shuffle=True, 
        num_workers=config['num_workers'], 
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=config['batch_size'],
        shuffle=False, 
        num_workers=config['num_workers'], 
        pin_memory=True
    )
    
    print(f"   Train batches: {len(train_loader)}")
    print(f"   Val batches:   {len(val_loader)}")
    
    # 3. ëª¨ë¸ ìƒì„±
    print(f"\nğŸ”§ Creating model...")
    
    # â­ Sigmoid ì‚¬ìš© ì—¬ë¶€ ê²°ì •
    use_sigmoid = (normalization is not None and 
                   normalization.get('type') == 'fixed_range')
    
    model = SimpleViT(
        img_size=lr_q_train.shape[1],
        patch_size=config['patch_size'],
        in_chans=1,
        out_chans=1,
        embed_dim=config['embed_dim'],
        depth=config['depth'],
        num_heads=config['num_heads'],
        mlp_ratio=4.,
        dropout=config['dropout'],
        use_sigmoid=use_sigmoid  # â­ ê³ ì • ë²”ìœ„ë©´ True
    )
    
    print(f"   Model: {type(model).__name__}")
    print(f"   Image size: {lr_q_train.shape[1]}x{lr_q_train.shape[2]}")
    print(f"   Patch size: {config['patch_size']}")
    print(f"   Embed dim: {config['embed_dim']}")
    print(f"   Depth: {config['depth']}")
    print(f"   Num heads: {config['num_heads']}")
    print(f"   Dropout: {config['dropout']}")
    print(f"   Use sigmoid: {use_sigmoid}")
    print(f"   Parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")
    
    # 4. Trainer ìƒì„±
    print(f"\nğŸ¯ Creating trainer...")
    trainer = BiasCorrectTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        device=config['device'],
        lr=config['lr'],
        weight_decay=config['weight_decay'],
        checkpoint_dir=config['checkpoint_dir'],
        plot_dir=config['plot_dir'],
        plot_every=config['plot_every'],
        quantiles=quantiles,
        normalization=normalization,  # â­ ê³ ì • ë²”ìœ„ ì •ë³´
        # í•˜ìœ„ í˜¸í™˜ì„±
        lr_stats=lr_stats,
        hr_stats=hr_stats
    )
    
    # 5. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    trainer.set_scheduler('cosine', config['num_epochs'])
    
    # 6. í•™ìŠµ ì‹œì‘
    print("\n" + "="*60)
    trainer.fit(config['num_epochs'], lr_q_val)
    
    return trainer


def get_default_config(use_fixed_range=True):
    """
    ê¸°ë³¸ ì„¤ì •
    
    Parameters:
    -----------
    use_fixed_range : bool
        ê³ ì • ë²”ìœ„ ë°©ì‹ ì‚¬ìš© ì—¬ë¶€
    """
    
    if use_fixed_range:
        # ê³ ì • ë²”ìœ„ ë°©ì‹ (ë” ì•ˆì •ì )
        return {
            'batch_size': 8,  # ì•½ê°„ ì¦ê°€
            'num_workers': 4,
            
            # SimpleViT with Sigmoid
            'patch_size': 8,      # ì ì ˆí•œ í¬ê¸°
            'embed_dim': 512,     # ì¶©ë¶„í•œ í‘œí˜„ë ¥
            'depth': 12,          # ê¹Šì´
            'num_heads': 8,       # í—¤ë“œ ìˆ˜
            'dropout': 0.1,       # ì ë‹¹í•œ ë“œë¡­ì•„ì›ƒ
            
            'num_epochs': 200,
            'lr': 1e-4,           # ì ë‹¹í•œ í•™ìŠµë¥ 
            'weight_decay': 0.01,
            
            'device': 'cuda:1',
            'checkpoint_dir': 'checkpoints/vit_fixed_range',
            'plot_dir': 'plots/vit_fixed_range',
            'plot_every': 5
        }
    else:
        # ê¸°ì¡´ ë°©ì‹ (Z-score)
        return {
            'batch_size': 4,
            'num_workers': 4,
            
            # SimpleViT without Sigmoid
            'patch_size': 4,
            'embed_dim': 256,
            'depth': 4,
            'num_heads': 4,
            'dropout': 0.1,
            
            'num_epochs': 200,
            'lr': 5e-5,
            'weight_decay': 0.01,
            
            'device': 'cuda:1',
            'checkpoint_dir': 'checkpoints/simple_vit',
            'plot_dir': 'plots/simple_vit',
            'plot_every': 5
        }


# â­ í¸ì˜ í•¨ìˆ˜: ê³ ì • ë²”ìœ„ í•™ìŠµ
def train_fixed_range(
    lr_q_train, hr_q_train,
    lr_q_val, hr_q_val,
    quantiles,
    lr_range=(260, 320),
    hr_range=(260, 320),
    custom_config=None
):
    """
    ê³ ì • ë²”ìœ„ ë°©ì‹ìœ¼ë¡œ í•™ìŠµ
    
    Parameters:
    -----------
    lr_q_train, hr_q_train : numpy.ndarray
        í›ˆë ¨ ë¶„ìœ„ìˆ˜ ë§µ [n_quantiles, H, W], [0, 1] ì •ê·œí™”
    lr_q_val, hr_q_val : numpy.ndarray
        ê²€ì¦ ë¶„ìœ„ìˆ˜ ë§µ [n_quantiles, H, W], [0, 1] ì •ê·œí™”
    quantiles : numpy.ndarray
        ë¶„ìœ„ìˆ˜ ë°°ì—´
    lr_range, hr_range : tuple
        ë¬¼ë¦¬ ë‹¨ìœ„ ë²”ìœ„ (min, max) in Kelvin
    custom_config : dict or None
        ì‚¬ìš©ì ì •ì˜ ì„¤ì • (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    """
    
    # ì •ê·œí™” ì •ë³´
    normalization = {
        'type': 'fixed_range',
        'lr_min': lr_range[0],
        'lr_max': lr_range[1],
        'hr_min': hr_range[0],
        'hr_max': hr_range[1]
    }
    
    # ì„¤ì •
    if custom_config is None:
        config = get_default_config(use_fixed_range=True)
    else:
        config = custom_config
    
    # í•™ìŠµ
    trainer = train_bias_correction(
        lr_q_train, hr_q_train,
        lr_q_val, hr_q_val,
        quantiles=quantiles,
        config=config,
        normalization=normalization
    )
    
    return trainer


# â­ í¸ì˜ í•¨ìˆ˜: í‘œì¤€ ë°©ì‹ í•™ìŠµ (í•˜ìœ„ í˜¸í™˜ì„±)
def train_standard(
    lr_q_train, hr_q_train,
    lr_q_val, hr_q_val,
    lr_stats, hr_stats,
    quantiles,
    custom_config=None
):
    """
    í‘œì¤€ ë°©ì‹ìœ¼ë¡œ í•™ìŠµ (Z-score ì •ê·œí™”)
    
    í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜
    """
    
    # ì„¤ì •
    if custom_config is None:
        config = get_default_config(use_fixed_range=False)
    else:
        config = custom_config
    
    # í•™ìŠµ
    trainer = train_bias_correction(
        lr_q_train, hr_q_train,
        lr_q_val, hr_q_val,
        quantiles=quantiles,
        config=config,
        normalization=None,  # í‘œì¤€ ë°©ì‹
        lr_stats=lr_stats,
        hr_stats=hr_stats
    )
    
    return trainer


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    import pickle
    
    print("="*60)
    print("Training Script - Usage Example")
    print("="*60)
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ Loading data...")
    with open('quantile_maps_fixed_range.pkl', 'rb') as f:
        qdata = pickle.load(f)
    
    lr_q_train, hr_q_train = qdata['train']
    lr_q_val, hr_q_val = qdata['val']
    quantiles = qdata['quantiles']
    normalization = qdata['normalization']
    
    print(f"   Loaded: {lr_q_train.shape}")
    
    # 2. ê³ ì • ë²”ìœ„ ë°©ì‹ í•™ìŠµ
    print("\nğŸš€ Method 1: Fixed Range Training")
    
    trainer = train_fixed_range(
        lr_q_train, hr_q_train,
        lr_q_val, hr_q_val,
        quantiles=quantiles,
        lr_range=(normalization['lr_min'], normalization['lr_max']),
        hr_range=(normalization['hr_min'], normalization['hr_max']),
        custom_config=None  # ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
    )
    
    print(f"\nâœ… Training completed!")
    print(f"   Best loss: {trainer.best_loss:.6f}")
    
    # 3. ë˜ëŠ” ì§ì ‘ í˜¸ì¶œ
    print("\nğŸš€ Method 2: Direct Call")
    
    config = get_default_config(use_fixed_range=True)
    config['num_epochs'] = 100  # ì—í­ ìˆ˜ì •
    
    trainer2 = train_bias_correction(
        lr_q_train, hr_q_train,
        lr_q_val, hr_q_val,
        quantiles=quantiles,
        config=config,
        normalization=normalization
    )
    
    print("\n" + "="*60)